{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#biodiversityobservationnetworksjl","title":"BiodiversityObservationNetworks.jl","text":"<p>The purpose of this package is to provide a high-level, extensible, modular interface to the selection of sampling point for biodiversity processes in space. It is based around a collection of types representing point selection algorithms, used to select the most informative sampling points based on raster data. Specifically, many algorithms work from a layer indicating entropy of a model based prediction at each location.</p> <p>This package is in development</p> <p>The <code>BiodiversityObservationNetworks.jl</code> package is currently under development. The API is not expected to change a lot, but it may change in order to facilitate the integration of new features.</p> <p></p> <p></p>"},{"location":"#high-level-types","title":"High-level types","text":"<p># <code>BiodiversityObservationNetworks.BONSampler</code> \u2014 Type.</p> <pre><code>BONSampler\n</code></pre> <p>A union of the abstract types <code>BONSeeder</code> and <code>BONRefiner</code>. Both types return a tuple with the coordinates as a vector of <code>CartesianIndex</code>, and the weight matrix as a <code>Matrix</code> of <code>AbstractFloat</code>, in that order.</p> <p>source</p> <p># <code>BiodiversityObservationNetworks.BONSeeder</code> \u2014 Type.</p> <pre><code>abstract type BONSeeder end\n</code></pre> <p>A <code>BONSeeder</code> is an algorithm for proposing sampling locations using a raster of weights, represented as a matrix, in each cell.</p> <p>source</p> <p># <code>BiodiversityObservationNetworks.BONRefiner</code> \u2014 Type.</p> <pre><code>abstract type BONRefiner end\n</code></pre> <p>A <code>BONRefiner</code> is an algorithm for proposing sampling locations by refining a set of candidate points to a smaller set of 'best' points.</p> <p>source</p> <p></p> <p></p>"},{"location":"#seeder-and-refiner-functions","title":"Seeder and refiner functions","text":"<p># <code>BiodiversityObservationNetworks.seed</code> \u2014 Function.</p> <pre><code>seed(sampler::ST, uncertainty::Matrix{T})\n</code></pre> <p>Produces a set of candidate sampling locations in a vector <code>coords</code> of length numpoints from a raster <code>uncertainty</code> using <code>sampler</code>, where <code>sampler</code> is a <code>BONSeeder</code>.   </p> <p>source</p> <pre><code>seed!(coords::Vector{CartesianIndex}, sampler::ST)\n</code></pre> <p>The curried version of <code>seed!</code>, which returns a function that acts on the input uncertainty layer passed to the curried function (<code>u</code> below).</p> <p>source</p> <p># <code>BiodiversityObservationNetworks.seed!</code> \u2014 Function.</p> <pre><code>seed!(coords::Vector{CartesianIndex}, sampler::ST, uncertainty::Matrix{T})\n</code></pre> <p>Puts a set of candidate sampling locations in the preallocated vector <code>coords</code> from a raster <code>uncertainty</code> using <code>sampler</code>, where <code>sampler</code> is a <code>BONSeeder</code>.</p> <ul> <li>Seeder's work on rasters, refiners work on set of coordinates.</li> </ul> <p>source</p> <pre><code>seed!(coords::Vector{CartesianIndex}, sampler::ST)\n</code></pre> <p>The curried version of <code>seed!</code>, which returns a function that acts on the input uncertainty layer passed to the curried function (<code>u</code> below).</p> <p>source</p> <p># <code>BiodiversityObservationNetworks.refine</code> \u2014 Function.</p> <pre><code>refine(pool::Vector{CartesianIndex}, sampler::ST, uncertainty::Matrix{T})\n</code></pre> <p>Refines a set of candidate sampling locations and returns a vector <code>coords</code> of length numpoints from a vector  of coordinates <code>pool</code> using <code>sampler</code>, where <code>sampler</code> is a <code>BONRefiner</code>.</p> <p>source</p> <pre><code>refine(sampler::BONRefiner)\n</code></pre> <p>Returns a curried function of <code>refine</code> with two methods: both are using the output of <code>seed</code>, one in its packed form, the other in its splatted form.</p> <p>source</p> <pre><code>refine(pack, sampler::BONRefiner)\n</code></pre> <p>Calls <code>refine</code> on the appropriatedly splatted version of <code>pack</code>.</p> <p>source</p> <p># <code>BiodiversityObservationNetworks.refine!</code> \u2014 Function.</p> <pre><code>refine!(cooords::Vector{CartesianIndex}, pool::Vector{CartesianIndex}, sampler::ST, uncertainty::Matrix{T})\n</code></pre> <p>Refines a set of candidate sampling locations in the preallocated vector <code>coords</code> from a vector  of coordinates <code>pool</code> using <code>sampler</code>, where <code>sampler</code> is a <code>BONRefiner</code>.</p> <p>source</p> <pre><code>refine!(cooords::Vector{CartesianIndex}, pool::Vector{CartesianIndex}, sampler::ST, uncertainty::Matrix{T})\n</code></pre> <p>The curried version of <code>refine!</code>, which returns a function that acts on the input coordinate pool passed to the curried function (<code>p</code> below).</p> <p>source</p> <p></p> <p></p>"},{"location":"#seeder-algorithms","title":"Seeder algorithms","text":"<p># <code>BiodiversityObservationNetworks.BalancedAcceptance</code> \u2014 Type.</p> <pre><code>BalancedAcceptance\n</code></pre> <p>A <code>BONSeeder</code> that uses Balanced-Acceptance Sampling (Van-dem-Bates et al. 2017 https://doi.org/10.1111/2041-210X.13003)</p> <p>source</p> <p></p> <p></p>"},{"location":"#refiner-algorithms","title":"Refiner algorithms","text":"<p># <code>BiodiversityObservationNetworks.AdaptiveSpatial</code> \u2014 Type.</p> <pre><code>AdaptiveSpatial\n</code></pre> <p>...</p> <p>numpoints, an Integer (def. 50), specifying the number of points to use.</p> <p>\u03b1, an AbstractFloat (def. 1.0), specifying ...</p> <p>source</p> <p># <code>BiodiversityObservationNetworks.Uniqueness</code> \u2014 Type.</p> <pre><code>Uniqueness\n</code></pre> <p>A <code>BONRefiner</code>.</p> <p>source</p> <p></p> <p></p>"},{"location":"#helper-functions","title":"Helper functions","text":"<p># <code>BiodiversityObservationNetworks.squish</code> \u2014 Function.</p> <pre><code>squish(layers, W, \u03b1)\n</code></pre> <p>Takes a set of <code>n</code> layers and squishes them down to a single layer.</p> <pre><code>    numcolumns = size(W,2)\n    for i in 1:numcolumns\n        W[:,i] ./= sum(W[:,i])\n    end\n</code></pre> <p>For a coordinate in the raster (i,j), denote the vector of values across all locations at that coordinate v\u20d7\u1d62\u2c7c. The value at that coordinate in squished layer, s\u20d7\u1d62\u2c7c, is computed in two steps.</p> <p>(1): First we apply a weights matrix, <code>W``, with</code>n<code>rows and</code>m<code>columns (</code>m<code>&lt;</code>n<code>), to reduce the initial</code>n<code>layers down to a set of</code>m` layers, each of which corresponds  to a particular target of optimization. For example, we may want to propose sampling  locations that are optimized to best sample  abalance multiple criteria, like (a) the  current distribution of a species and (b) if that distribution is changing over time.</p> <p>Each entry in the weights matrix <code>W</code> corresponds to the 'importance' of the layer in the corresponding row to the successful measurement of the target of the corresponding column. As such, each column of <code>W</code> must sum to 1.0. using Optim</p> <p>For each location, the value of the condensed layer <code>t\u1d62</code>, corresponding to target <code>i</code>, at  coordinate (i,j) is given by the dot product of v\u20d7\u1d62\u2c7c and the <code>i</code>-th column of <code>W</code>.</p> <p>(2): Apply a weighted average across each target layer. To produce the final output layer, we apply a weighted average to each target layer, where the weights are provided in the vector \u03b1\u20d7 of length <code>m</code>.</p> <p>The final value of the squished layer at (i,j) is given by s\u20d7\u1d62\u2c7c = \u2211\u2093 \u03b1\u2093*t\u1d62\u2c7c(x), where t\u1d62\u2c7c(x) is the value of the x-th target layer at (i,j).</p> <p>source</p> <p># <code>BiodiversityObservationNetworks.entropize!</code> \u2014 Function.</p> <pre><code>entropize!(U::Matrix{AbstractFloat}, A::Matrix{Number})\n</code></pre> <p>This function turns a matrix <code>A</code> (storing measurement values) into pixel-wise entropy values, stored in a matrix <code>U</code> (that is previously allocated).</p> <p>Pixel-wise entropy is determined by measuring the empirical probability of randomly picking a value in the matrix that is either lower or higher than the pixel value. The entropy of both these probabilities are calculated using the -p\u00d7log(2,p) formula. The entropy of the pixel is the sum of the two entropies, so that it is close to 1 for values close to the median, and close to 0 for values close to the extreme of the distribution.</p> <p>source</p> <p># <code>BiodiversityObservationNetworks.entropize</code> \u2014 Function.</p> <pre><code>entropize(A::Matrix{Number})\n</code></pre> <p>Allocation version of <code>entropize!</code>.</p> <p>source</p>"},{"location":"bibliography/","title":"Bibliography","text":""},{"location":"bibliography/#references","title":"References","text":""},{"location":"vignettes/entropize/","title":"Entropize","text":""},{"location":"vignettes/entropize/#getting-the-entropy-matrix","title":"Getting the entropy matrix","text":"<p>For some applications, we want to place points to capture the maximum amount of information, which is to say that we want to sample a balance of entropy values, as opposed to absolute values. In this vignette, we will walk through an example using the <code>entropize</code> function to convert raw data to entropy values. </p> <pre><code>using BiodiversityObservationNetworks\nusing NeutralLandscapes\nusing Plots\n</code></pre> <p>Entropy is problem-specific</p> <p>The solution presented in this vignette is a least-assumption solution based on the empirical values given in a matrix of measurements. In a lot of situations, this is not the entropy that you want. For example, if your pixels are storing probabilities of Bernoulli events, you can directly use the entropy of the events in the entropy matrix.</p> <p>We start by generating a random matrix of measurements:</p> <pre><code>measurements = rand(MidpointDisplacement(), (200, 200)) .* 100\nheatmap(measurements)\n</code></pre> <p> </p> <p>Using the <code>entropize</code> function will convert these values into entropy at the pixel scale: </p> <pre><code>U = entropize(measurements)\nheatmap(U')\n</code></pre> <p> </p> <p>The values closest to the median of the distribution have the highest entropy, and the values closest to its extrema have an entropy of 0. The entropy matrix is guaranteed to have values on the unit interval.</p> <p>We can use <code>entropize</code> as part of a pipeline, and overlay the points optimized based on entropy on the measurement map:</p> <pre><code>locations =\n    measurements |&gt; entropize |&gt; seed(BalancedAcceptance(; numpoints = 100)) |&gt; first\nheatmap(U')\nscatter!(\n    [x[1] for x in locations],\n    [x[2] for x in locations];\n    ms = 2.5,\n    mc = :white,\n    label = \"\",\n)\n</code></pre> <p> </p>"},{"location":"vignettes/overview/","title":"Overview","text":""},{"location":"vignettes/overview/#an-introduction-to-biodiversityobservationnetworks","title":"An introduction to BiodiversityObservationNetworks","text":"<p>In this vignette, we will walk through the basic functionalities of the package, by generating a random uncertainty matrix, and then using a seeder and a refiner to decide which locations should be sampled in order to gain more insights about the process generating this entropy. </p> <pre><code>using BiodiversityObservationNetworks\nusing NeutralLandscapes\nusing Plots\n</code></pre> <p>In order to simplify the process, we will use the NeutralLandscapes package to generate a 100\u00d7100 pixels landscape, where each cell represents the entropy (or information content) in a unit we can sample:</p> <pre><code>U = rand(MidpointDisplacement(0.5), (100, 100))\nheatmap(U'; aspectratio = 1, frame = :none, c = :lapaz)\n</code></pre> <p> </p> <p>In practice, this uncertainty matrix is likely to be derived from an application of the hyper-parameters optimization step, which is detailed in other vignettes.</p> <p>The first step of defining a series of locations to sample is to use a <code>BONSeeder</code>, which will generate a number of relatively coarse proposals that cover the entire landscape, and have a balanced distribution in space. We do so using the <code>BalancedAcceptance</code> sampler, which can be tweaked to capture more (or less) uncertainty. To start with, we will extract 200 candidate points, i.e. 200 possible locations which will then be refined. </p> <pre><code>pack = seed(BalancedAcceptance(; numpoints = 200), U);\n</code></pre> <pre><code>(CartesianIndex[CartesianIndex(81, 65), CartesianIndex(75, 93), CartesianIndex(100, 41), CartesianIndex(27, 52), CartesianIndex(89, 11), CartesianIndex(33, 22), CartesianIndex(83, 55), CartesianIndex(21, 89), CartesianIndex(71, 33), CartesianIndex(46, 67)  \u2026  CartesianIndex(87, 17), CartesianIndex(49, 28), CartesianIndex(99, 61), CartesianIndex(77, 76), CartesianIndex(14, 20), CartesianIndex(89, 31), CartesianIndex(8, 65), CartesianIndex(58, 98), CartesianIndex(33, 3), CartesianIndex(83, 36)], [0.6128903142912409 0.5851788303953241 \u2026 0.4982193818619701 0.5107397261701937; 0.6590836567467002 0.6907696417234754 \u2026 0.49318941188547416 0.49854632556992157; \u2026 ; 0.42047331660217674 0.5110755415297855 \u2026 0.7113710731051456 0.6885975225393581; 0.4451462522722331 0.39204346006231217 \u2026 0.6990479158387574 0.6645578031164386])\n</code></pre> <p>The output of a <code>BONSampler</code> (whether at the seeding or refinement step) is always a tuple, storing in the first position a vector of <code>CartesianIndex</code> elements, and in the second position the matrix given as input. We can have a look at the first five points: </p> <pre><code>first(pack)[1:5]\n</code></pre> <pre><code>5-element Vector{CartesianIndex}:\n CartesianIndex(81, 65)\n CartesianIndex(75, 93)\n CartesianIndex(100, 41)\n CartesianIndex(27, 52)\n CartesianIndex(89, 11)\n</code></pre> <p>Although returning the input matrix may seem redundant, it actually allows to chain samplers together to build pipelines that take a matrix as input, and return a set of places to sample as outputs; an example is given below.</p> <p>The positions of locations to sample are given as a vector of <code>CartesianIndex</code>, which are coordinates in the uncertainty matrix. Once we have generated a candidate proposal, we can further refine it using a <code>BONRefiner</code> \u2013 in this case, <code>AdaptiveSpatial</code>, which performs adaptive spatial sampling (maximizing the distribution of entropy while minimizing spatial auto-correlation).</p> <pre><code>candidates, uncertainty = pack\nlocations, _ = refine(candidates, AdaptiveSpatial(; numpoints = 50), uncertainty)\nlocations[1:5]\n</code></pre> <pre><code>5-element Vector{CartesianIndex}:\n CartesianIndex(63, 99)\n CartesianIndex(62, 96)\n CartesianIndex(58, 98)\n CartesianIndex(53, 94)\n CartesianIndex(58, 90)\n</code></pre> <p>The reason we start from a candidate set of points is that some algorithms struggle with full landscapes, and work much better with a sub-sample of them. There is no hard rule (or no heuristic) to get a sense for how many points should be generated at the seeding step, and so experimentation is a must!</p> <p>The previous code examples used a version of the <code>seed</code> and <code>refine</code> functions that is very useful if you want to change arguments between steps, or examine the content of the candidate pool of points. In addition to this syntax, both functions have a curried version that allows chaining them together using pipes (<code>|&gt;</code>):</p> <pre><code>locations =\n    U |&gt;\n    seed(BalancedAcceptance(; numpoints = 200)) |&gt;\n    refine(AdaptiveSpatial(; numpoints = 50)) |&gt;\n    first\n</code></pre> <pre><code>50-element Vector{CartesianIndex}:\n CartesianIndex(69, 99)\n CartesianIndex(85, 88)\n CartesianIndex(73, 100)\n CartesianIndex(66, 96)\n CartesianIndex(70, 94)\n CartesianIndex(62, 95)\n CartesianIndex(67, 90)\n CartesianIndex(70, 89)\n CartesianIndex(68, 86)\n CartesianIndex(60, 90)\n \u22ee\n CartesianIndex(100, 12)\n CartesianIndex(26, 23)\n CartesianIndex(76, 57)\n CartesianIndex(13, 90)\n CartesianIndex(63, 5)\n CartesianIndex(88, 72)\n CartesianIndex(82, 27)\n CartesianIndex(45, 9)\n CartesianIndex(95, 42)\n</code></pre> <p>This works because <code>seed</code> and <code>refine</code> have curried versions that can be used directly in a pipeline. Proposed sampling locations can then be overlayed onto the original uncertainty matrix: </p> <pre><code>plt = heatmap(U'; aspectratio = 1, frame = :none, c = :lapaz)\nscatter!(plt, [x[1] for x in locations], [x[2] for x in locations], ms=2.5, mc=:white, label=\"\")\n</code></pre> <p> </p>"},{"location":"vignettes/uniqueness/","title":"Uniqueness.jl","text":""},{"location":"vignettes/uniqueness/#selecting-environmentally-unique-locations","title":"Selecting environmentally unique locations","text":"<p>For some applications, we want to sample a set of locations that cover a broad range of values in environment space. Another way to rephrase this problem is to say we want to find the set of points with the least covariance in their environmental values.  </p> <p>To do this, we use a <code>BONRefiner</code> called <code>Uniqueness</code>. We'll start by loading the required packages. </p> <pre><code>using BiodiversityObservationNetworks\nusing SpeciesDistributionToolkit\nusing StatsBase\nusing NeutralLandscapes\nusing Plots\n</code></pre> <pre><code>[ Info: Loading NeutralLandscapes support for SimpleSDMLayers.jl...\n</code></pre> <p>Consider setting your SDMLAYERS_PATH</p> <p>When accessing data using <code>SimpleSDMDatasets.jl</code>, it is best to set the <code>SDM_LAYERSPATH</code> environmental variable to tell <code>SimpleSDMDatasets.jl</code> where to download data. This can be done by setting <code>ENV[\"SDMLAYERS_PATH\"] = \"/home/user/Data/\"</code> or similar in the <code>~/.julia/etc/julia/startup.jl</code> file. (Note this will be different depending on where <code>julia</code> is installed.)</p> <p>```@example 1 bbox = (left=-83.0, bottom=46.4, right=-55.2, top=63.7); temp, precip, elevation =      convert(Float32, SimpleSDMPredictor(RasterData(WorldClim2, AverageTemperature); bbox...)),     convert(Float32, SimpleSDMPredictor(RasterData(WorldClim2, Precipitation); bbox...)),     convert(Float32, SimpleSDMPredictor(RasterData(WorldClim2, Elevation); bbox...)); <pre><code>Now we'll use the `stack` function to combine our four environmental layers into a single, 3-dimensional array, which we'll pass to our `Uniqueness` refiner.\n\n\n```@example 1\nlayers = BiodiversityObservationNetworks.stack([temp,precip,elevation]);\n</code></pre></p> <p>this requires NeutralLandscapes v0.1.2</p> <p>```@example 1 uncert = rand(MidpointDisplacement(0.8), size(temp), mask=temp); heatmap(uncert, aspectratio=1, frame=:box)  <pre><code>Now we'll get a set of candidate points from a BalancedAcceptance seeder that has no bias toward higher uncertainty values.\n\n\n```@example 1\ncandpts, uncert = uncert |&gt; seed(BalancedAcceptance(numpoints=100, \u03b1=0.0)); \n</code></pre></p> <p>Now we'll <code>refine</code> our <code>100</code> candidate points down to the 30 most environmentally unique.</p> <p>```@example 1 finalpts, uncert = refine(candpts, Uniqueness(;numpoints=30, layers=layers), uncert)</p> <p>heatmap(uncert) scatter!([p[2] for p in candpts], [p[1] for p in candpts], fa=0.0, msc=:white, label=\"Candidate Points\") scatter!([p[2] for p in finalpts], [p[1] for p in finalpts], c=:dodgerblue, msc=:white, label=\"Selected Points\") ```</p>"}]}